{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install matplotlib seaborn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: numpy>=1.19.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.11.0)\nRequirement already satisfied: pandas in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: numpy>=1.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas) (2022.5)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\nRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (3.7.1)\nRequirement already satisfied: seaborn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.13.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (3.2.3)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (9.2.0)\nRequirement already satisfied: numpy>=1.20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (4.51.0)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: pandas>=1.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from seaborn) (1.5.3)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2022.5)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1749715890046
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "# Log the start of data loading\n",
        "logging.info(\"Loading dataset...\")\n",
        "\n",
        "# Load Breast Cancer dataset and convert to DataFrame\n",
        "data = load_breast_cancer()\n",
        "logging.info(\"Dataset loaded successfully.\")\n",
        "\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Explore the dataset\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n0        17.99         10.38          122.80     1001.0          0.11840   \n1        20.57         17.77          132.90     1326.0          0.08474   \n2        19.69         21.25          130.00     1203.0          0.10960   \n3        11.42         20.38           77.58      386.1          0.14250   \n4        20.29         14.34          135.10     1297.0          0.10030   \n\n   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n0           0.27760          0.3001              0.14710         0.2419   \n1           0.07864          0.0869              0.07017         0.1812   \n2           0.15990          0.1974              0.12790         0.2069   \n3           0.28390          0.2414              0.10520         0.2597   \n4           0.13280          0.1980              0.10430         0.1809   \n\n   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n0                 0.07871  ...          17.33           184.60      2019.0   \n1                 0.05667  ...          23.41           158.80      1956.0   \n2                 0.05999  ...          25.53           152.50      1709.0   \n3                 0.09744  ...          26.50            98.87       567.7   \n4                 0.05883  ...          16.67           152.20      1575.0   \n\n   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n0            0.1622             0.6656           0.7119                0.2654   \n1            0.1238             0.1866           0.2416                0.1860   \n2            0.1444             0.4245           0.4504                0.2430   \n3            0.2098             0.8663           0.6869                0.2575   \n4            0.1374             0.2050           0.4000                0.1625   \n\n   worst symmetry  worst fractal dimension  target  \n0          0.4601                  0.11890       0  \n1          0.2750                  0.08902       0  \n2          0.3613                  0.08758       0  \n3          0.6638                  0.17300       0  \n4          0.2364                  0.07678       0  \n\n[5 rows x 31 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 31 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   mean radius              569 non-null    float64\n 1   mean texture             569 non-null    float64\n 2   mean perimeter           569 non-null    float64\n 3   mean area                569 non-null    float64\n 4   mean smoothness          569 non-null    float64\n 5   mean compactness         569 non-null    float64\n 6   mean concavity           569 non-null    float64\n 7   mean concave points      569 non-null    float64\n 8   mean symmetry            569 non-null    float64\n 9   mean fractal dimension   569 non-null    float64\n 10  radius error             569 non-null    float64\n 11  texture error            569 non-null    float64\n 12  perimeter error          569 non-null    float64\n 13  area error               569 non-null    float64\n 14  smoothness error         569 non-null    float64\n 15  compactness error        569 non-null    float64\n 16  concavity error          569 non-null    float64\n 17  concave points error     569 non-null    float64\n 18  symmetry error           569 non-null    float64\n 19  fractal dimension error  569 non-null    float64\n 20  worst radius             569 non-null    float64\n 21  worst texture            569 non-null    float64\n 22  worst perimeter          569 non-null    float64\n 23  worst area               569 non-null    float64\n 24  worst smoothness         569 non-null    float64\n 25  worst compactness        569 non-null    float64\n 26  worst concavity          569 non-null    float64\n 27  worst concave points     569 non-null    float64\n 28  worst symmetry           569 non-null    float64\n 29  worst fractal dimension  569 non-null    float64\n 30  target                   569 non-null    int64  \ndtypes: float64(30), int64(1)\nmemory usage: 137.9 KB\nNone\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1749716398583
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_data(data):\n",
        "    try:\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise ValueError(\"Input must be a pandas DataFrame.\")\n",
        "        if data.isnull().values.any():\n",
        "            raise ValueError(\"Missing values detected in the dataset.\")\n",
        "        print(\"Data validation successful.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Data validation error: {e}\")\n",
        "\n",
        "# Validate the dataset\n",
        "validate_data(df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Data validation successful.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1749716100688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Log the start of preprocessing\n",
        "logging.info(\"Starting data preprocessing...\")\n",
        "\n",
        "# Handle missing data (example: filling missing values with the median)\n",
        "df.fillna(df.median(), inplace=True)\n",
        "logging.info(\"Missing values filled with median.\")\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Log the completion of preprocessing\n",
        "logging.info(\"Data preprocessing completed.\")\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1749716913087
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train logistic regression model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Logistic Regression Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1749716915556
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train decision tree model\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
        "print(f\"Decision Tree Accuracy: {accuracy_tree * 100:.2f}%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Decision Tree Accuracy: 93.86%\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1749716919115
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Log the start of model training\n",
        "logging.info(\"Starting model training...\")\n",
        "\n",
        "# Implement a decision tree model with error handling\n",
        "try:\n",
        "    # Train the decision tree model\n",
        "    model = DecisionTreeClassifier()\n",
        "    model.fit(X_train, y_train)\n",
        "    logging.info(\"Model trained successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during model training: {e}\")\n",
        "\n",
        "\n",
        "# Example logging of training accuracy (if applicable)\n",
        "accuracy = model.score(X_train, y_train)\n",
        "logging.info(f\"Training accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Log the start of predictions\n",
        "logging.info(\"Starting model predictions...\")\n",
        "\n",
        "try:\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "    logging.info(\"Predictions made successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during predictions: {e}\")\n",
        "\n",
        "# Log the output (in production systems, limit the amount of data logged)\n",
        "logging.info(f\"Prediction output: {predictions[:5]}\")  # Log only first 5 predictions"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1749716920455
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(f\"SVM Accuracy: {accuracy_svm * 100:.2f}%\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SVM Accuracy: 94.74%\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1749716922213
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate performance\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Logistic Regression - Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Logistic Regression - Precision: 0.97, Recall: 0.96, F1 Score: 0.96\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1749716923854
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}