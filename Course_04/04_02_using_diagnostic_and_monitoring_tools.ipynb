{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create and save a sample dataset\n",
        "data = {\n",
        "    \"customer_id\": [1, 2, 3, 4, 5],\n",
        "    \"membership_level\": [\"Bronze\", \"Silver\", \"Gold\", \"Silver\", \"Bronze\"]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_filename = \"customer_data.csv\"\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Load the dataset\n",
        "incoming_data = pd.read_csv(csv_filename)\n",
        "\n",
        "# Validate the data\n",
        "def validate_data(df):\n",
        "    # Check for null values in 'customer_id'\n",
        "    if df['customer_id'].isnull().any():\n",
        "        print(\"Validation Error: 'customer_id' column contains null values.\")\n",
        "    else:\n",
        "        print(\"No null values in 'customer_id' column.\")\n",
        "\n",
        "    # Check that 'membership_level' contains only allowed values\n",
        "    allowed_values = {\"Bronze\", \"Silver\", \"Gold\"}\n",
        "    invalid_values = set(df['membership_level']) - allowed_values\n",
        "    if invalid_values:\n",
        "        print(f\"Validation Error: 'membership_level' contains invalid values: {invalid_values}\")\n",
        "    else:\n",
        "        print(\"All values in 'membership_level' are valid.\")\n",
        "\n",
        "# Run validation\n",
        "validate_data(incoming_data)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "No null values in 'customer_id' column.\nAll values in 'membership_level' are valid.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1749900423720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace\n",
        "\n",
        "# Connect to Azure ML Workspace\n",
        "workspace = Workspace.from_config()\n",
        "\n",
        "# Access the deployed service\n",
        "service_name = 'my-model-service'\n",
        "service = workspace.webservices[service_name]\n",
        "\n",
        "# Enable Application Insights if not already enabled\n",
        "if not service.app_insights_enabled:\n",
        "    service.update(enable_app_insights=True)\n",
        "    print(f\"Application Insights enabled for service: {service_name}\")\n",
        "else:\n",
        "    print(f\"Application Insights is already enabled for service: {service_name}\")\n",
        "\n",
        "# Check the Application Insights link\n",
        "print(f\"Application Insights URL: {service.scoring_uri}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply canary deployment to a limited number of users\n",
        "# This is pseudocode; it shows the business logic, but isnâ€™t a full implementation\n",
        "canary_deployment_successful = service.canary_deploy()\n",
        "if canary_deployment_successful:\n",
        "    print(\"Canary deployment successful. Proceeding to full deployment.\")\n",
        "else:\n",
        "    print(\"Canary deployment failed. Investigate issues before full deployment.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.monitor.query import MetricsQueryClient\n",
        "\n",
        "# Connect to Azure Metrics Client\n",
        "credential = DefaultAzureCredential()\n",
        "client = MetricsQueryClient(credential)\n",
        "\n",
        "# Define alert conditions\n",
        "alert_conditions = {\n",
        "    \"metric_name\": \"response_time\",\n",
        "    \"threshold\": 200,\n",
        "    \"operator\": \"GreaterThan\",\n",
        "    \"alert_action\": \"EmailNotification\"\n",
        "}\n",
        "print(\"Alert set up for response time exceeding 200 ms.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import random\n",
        "\n",
        "# Simulate response time metric\n",
        "response_time = 200  # Normal response time in milliseconds\n",
        "threshold = 300  # Alert threshold in milliseconds\n",
        "\n",
        "# Simulate an increase in response time\n",
        "response_time += random.randint(100, 200)  # Add random delay to exceed the threshold\n",
        "\n",
        "# Check if the response time exceeds the threshold\n",
        "if response_time > threshold:\n",
        "    print(f\"Alert: Response time exceeded! Current response time: {response_time} ms\")\n",
        "    # Trigger notification\n",
        "    print(\"Notification sent: Response time alert.\")\n",
        "    # Placeholder for initiating remediation (e.g., scaling up resources)\n",
        "    print(\"Initiating remediation: Scaling up resources.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate model accuracy metric\n",
        "model_accuracy = 0.85  # Normal accuracy\n",
        "threshold_accuracy = 0.80  # Minimum acceptable accuracy\n",
        "\n",
        "# Simulate a drop in accuracy\n",
        "model_accuracy -= random.uniform(0.1, 0.15)  # Decrease accuracy below the threshold\n",
        "\n",
        "# Check if the model accuracy drops below the threshold\n",
        "if model_accuracy < threshold_accuracy:\n",
        "    print(f\"Alert: Model accuracy dropped! Current accuracy: {model_accuracy:.2f}\")\n",
        "    # Trigger notification\n",
        "    print(\"Notification sent: Model accuracy alert.\")\n",
        "    # Placeholder for initiating remediation (e.g., retraining the model)\n",
        "    print(\"Initiating remediation: Retraining the model.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.20",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}